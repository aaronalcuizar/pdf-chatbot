import streamlit as st
import os
from typing import List, Dict
import time
import json
from datetime import datetime
import io

# Import our custom modules
from utils.pdf_processor import PDFProcessor
from utils.embeddings import EmbeddingsHandler
from utils.llm_handler import LLMHandler

# Page configuration
st.set_page_config(
    page_title="PDF Chatbot",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Updated CSS - FIXED: Reduced top and bottom margins to 24px
st.markdown("""
<style>
    /* Remove default padding and margins - UPDATED: Reduced to 24px */
    .main .block-container {
        padding-top: 24px;
        padding-bottom: 24px;
        max-width: 1200px;
    }
    
    /* Hide streamlit elements */
    .stApp > header {display: none;}
    .stApp > footer {display: none;}
    #MainMenu {display: none;}
    
    /* Chat messages */
    .chat-message {
        padding: 1.2rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }
    
    .user-message {
        background: linear-gradient(135deg, #4f46e5 0%, #7c3aed 100%);
        color: white;
        margin-left: 20%;
    }
    
    .ai-message {
        background: #f8fafc;
        color: #1e293b;
        border: 1px solid #e2e8f0;
        margin-right: 20%;
    }
    
    /* Document status */
    .doc-status {
        background: linear-gradient(135deg, #10b981 0%, #059669 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 1.5rem;
        text-align: center;
    }
    
    /* FIXED: Input styling with visible text */
    .stTextInput > div > div > input {
        border-radius: 25px !important;
        border: 2px solid #e2e8f0 !important;
        padding: 12px 20px !important;
        font-size: 14px !important;
        transition: all 0.3s ease !important;
        background: white !important;
        color: #1f2937 !important; /* Dark text color for visibility */
    }
    
    .stTextInput > div > div > input:focus {
        border-color: #4f46e5 !important;
        box-shadow: 0 0 0 3px rgba(79, 70, 229, 0.1) !important;
        color: #1f2937 !important; /* Ensure text stays dark when focused */
    }
    
    .stTextInput > div > div > input::placeholder {
        color: #9ca3af !important; /* Light gray placeholder */
        opacity: 1 !important;
    }
    
    /* Send button styling */
    .stButton > button {
        border-radius: 25px !important;
        background: linear-gradient(135deg, #4f46e5 0%, #7c3aed 100%) !important;
        border: none !important;
        color: white !important;
        font-weight: 600 !important;
        padding: 12px 24px !important;
        transition: all 0.3s ease !important;
        min-height: 48px !important;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 4px 15px rgba(79, 70, 229, 0.4) !important;
    }
    
    /* Remove unwanted margins from containers */
    .element-container {
        margin-bottom: 0 !important;
    }
    
    /* Save section styling */
    .save-section {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #e9ecef;
        margin: 1rem 0;
    }
    
    /* Welcome message improvements */
    .welcome-container {
        min-height: 60vh;
        display: flex;
        align-items: center;
        justify-content: center;
    }
    
    /* Quick questions styling */
    .quick-questions-text {
        font-size: 0.9rem;
        color: #6b7280;
        margin-bottom: 0.8rem;
        font-weight: 500;
        text-align: center;
    }
            
    
</style>
""", unsafe_allow_html=True)

# ============================================
# CONVERSATION SAVE/LOAD FUNCTIONS
# ============================================

def export_conversation_text() -> str:
    """Export conversation as formatted text"""
    if not st.session_state.messages:
        return "No conversation to export."
    
    # Get document info safely
    doc_info = st.session_state.get('doc_info', {}) or {}
    doc_name = doc_info.get('filename', 'Unknown Document')
    
    # Create header
    export_text = f"""PDF CHATBOT CONVERSATION EXPORT
=================================

Document: {doc_name}
Export Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Total Messages: {len(st.session_state.messages)}

=================================

"""
    
    # Add conversation
    for i, msg in enumerate(st.session_state.messages, 1):
        role = "ü§ñ AI Assistant" if msg["role"] == "assistant" else "üë§ You"
        export_text += f"[{i}] {role}:\n"
        export_text += f"{msg['content']}\n\n"
        export_text += "-" * 50 + "\n\n"
    
    export_text += f"""
=================================
End of Conversation Export
Generated by PDF Chatbot
=================================
"""
    
    return export_text

def export_conversation_json() -> str:
    """Export conversation as JSON"""
    if not st.session_state.messages:
        return "{}"
    
    doc_info = st.session_state.get('doc_info', {}) or {}
    
    export_data = {
        "export_info": {
            "timestamp": datetime.now().isoformat(),
            "document_name": doc_info.get('filename', 'Unknown'),
            "document_stats": {
                "word_count": doc_info.get('word_count', 0),
                "chunk_count": doc_info.get('chunk_count', 0)
            },
            "total_messages": len(st.session_state.messages)
        },
        "conversation": st.session_state.messages
    }
    
    return json.dumps(export_data, indent=2, ensure_ascii=False)

def export_conversation_markdown() -> str:
    """Export conversation as Markdown"""
    if not st.session_state.messages:
        return "# No conversation to export"
    
    doc_info = st.session_state.get('doc_info', {}) or {}
    doc_name = doc_info.get('filename', 'Unknown Document')
    
    markdown_text = f"""# PDF Chatbot Conversation

**Document:** {doc_name}  
**Export Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**Total Messages:** {len(st.session_state.messages)}

---

"""
    
    for i, msg in enumerate(st.session_state.messages, 1):
        if msg["role"] == "user":
            markdown_text += f"## üë§ Question {i//2 + 1}\n\n{msg['content']}\n\n"
        else:
            markdown_text += f"## ü§ñ AI Response\n\n{msg['content']}\n\n---\n\n"
    
    markdown_text += """
*Generated by PDF Chatbot*
"""
    
    return markdown_text

def save_conversation_sidebar():
    """Add save conversation options to sidebar"""
    if st.session_state.messages:
        st.sidebar.markdown("---")
        st.sidebar.subheader("üíæ Save Conversation")
        
        # Save format selection
        save_format = st.sidebar.selectbox(
            "Export Format",
            ["Text (.txt)", "Markdown (.md)", "JSON (.json)"],
            help="Choose format for saving conversation"
        )
        
        # Generate filename safely
        doc_info = st.session_state.get('doc_info', {}) or {}
        doc_name = doc_info.get('filename', 'conversation')
        # Clean filename
        clean_doc_name = "".join(c for c in doc_name if c.isalnum() or c in (' ', '-', '_')).rstrip()
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        if save_format == "Text (.txt)":
            filename = f"chat_{clean_doc_name}_{timestamp}.txt"
            content = export_conversation_text()
            mime_type = "text/plain"
        elif save_format == "Markdown (.md)":
            filename = f"chat_{clean_doc_name}_{timestamp}.md"
            content = export_conversation_markdown()
            mime_type = "text/markdown"
        else:  # JSON
            filename = f"chat_{clean_doc_name}_{timestamp}.json"
            content = export_conversation_json()
            mime_type = "application/json"
        
        # Download button
        st.sidebar.download_button(
            label="üì• Download Conversation",
            data=content,
            file_name=filename,
            mime=mime_type,
            help=f"Download conversation as {save_format}",
            use_container_width=True
        )
        
        # Conversation stats
        if st.sidebar.button("üìä Show Stats", use_container_width=True):
            total_messages = len(st.session_state.messages)
            user_messages = len([m for m in st.session_state.messages if m["role"] == "user"])
            ai_messages = len([m for m in st.session_state.messages if m["role"] == "assistant"])
            
            st.sidebar.metric("Total Messages", total_messages)
            st.sidebar.metric("Your Questions", user_messages) 
            st.sidebar.metric("AI Responses", ai_messages)
            
            # Calculate total characters
            total_chars = sum(len(m["content"]) for m in st.session_state.messages)
            st.sidebar.metric("Total Characters", f"{total_chars:,}")

def load_conversation_sidebar():
    """Add load conversation option to sidebar"""
    st.sidebar.subheader("üìÇ Load Conversation")
    
    uploaded_chat = st.sidebar.file_uploader(
        "Upload Previous Chat",
        type=['json'],
        help="Load a previously saved conversation (JSON format only)",
        key="chat_uploader"
    )
    
    if uploaded_chat:
        try:
            # Read the JSON file
            chat_data = json.loads(uploaded_chat.read().decode('utf-8'))
            
            if 'conversation' in chat_data:
                # Validate the format
                if isinstance(chat_data['conversation'], list):
                    # Show preview
                    st.sidebar.success(f"‚úÖ Found {len(chat_data['conversation'])} messages")
                    
                    if 'export_info' in chat_data:
                        info = chat_data['export_info']
                        st.sidebar.info(f"üìÑ Document: {info.get('document_name', 'Unknown')}")
                        st.sidebar.info(f"üìÖ Date: {info.get('timestamp', 'Unknown')}")
                    
                    # Load button
                    if st.sidebar.button("üîÑ Load This Conversation"):
                        st.session_state.messages = chat_data['conversation']
                        st.sidebar.success("‚úÖ Conversation loaded!")
                        st.rerun()
                else:
                    st.sidebar.error("‚ùå Invalid conversation format")
            else:
                st.sidebar.error("‚ùå No conversation data found")
                
        except json.JSONDecodeError:
            st.sidebar.error("‚ùå Invalid JSON file")
        except Exception as e:
            st.sidebar.error(f"‚ùå Error loading file: {str(e)}")

# ============================================
# MAIN APPLICATION FUNCTIONS  
# ============================================

def initialize_session():
    """Initialize session state"""
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'document_ready' not in st.session_state:
        st.session_state.document_ready = False
    if 'doc_info' not in st.session_state:
        st.session_state.doc_info = None
    if 'embeddings' not in st.session_state:
        st.session_state.embeddings = None
    if 'llm' not in st.session_state:
        st.session_state.llm = LLMHandler()
    if 'pdf_proc' not in st.session_state:
        st.session_state.pdf_proc = PDFProcessor()
    # Add counter to force input refresh
    if 'input_counter' not in st.session_state:
        st.session_state.input_counter = 0

def sidebar():
    """Enhanced sidebar with save/load functionality"""
    st.sidebar.title("ü§ñ PDF Chatbot")
    
    # Status
    st.sidebar.subheader("üìä Status")
    if st.session_state.document_ready:
        st.sidebar.success("‚úÖ Document Ready")
        if st.session_state.doc_info:
            st.sidebar.info(f"üìÑ {st.session_state.doc_info['filename']}")
            st.sidebar.info(f"üìù {st.session_state.doc_info['word_count']:,} words")
            
            # Memory status
            if hasattr(st.session_state, 'llm') and hasattr(st.session_state.llm, 'conversation_memory') and st.session_state.llm.conversation_memory:
                memory_count = len(st.session_state.llm.conversation_memory)
                st.sidebar.info(f"üß† Context: {memory_count} exchanges")
    else:
        st.sidebar.info("üì§ Upload a PDF to start")
    
    # Upload
    st.sidebar.subheader("üìÅ Upload")
    uploaded_file = st.sidebar.file_uploader("Choose PDF", type=['pdf'])
    
    if uploaded_file and not st.session_state.document_ready:
        if process_pdf(uploaded_file):
            st.rerun()
    
    # Controls
    st.sidebar.subheader("üõ†Ô∏è Controls")
    
    col1, col2 = st.sidebar.columns(2)
    with col1:
        if st.button("üóëÔ∏è Clear Chat", use_container_width=True):
            st.session_state.messages = []
            if hasattr(st.session_state, 'llm') and hasattr(st.session_state.llm, 'clear_memory'):
                st.session_state.llm.clear_memory()
            st.rerun()
    
    with col2:
        if st.button("üîÑ New Document", use_container_width=True):
            reset_session()
            st.rerun()
    
    # Save/Load functionality
    save_conversation_sidebar()
    load_conversation_sidebar()

def process_pdf(file):
    """Process uploaded PDF"""
    try:
        with st.spinner("Processing PDF..."):
            # Process
            result = st.session_state.pdf_proc.process_pdf(file, chunk_size=1000)
            if not result:
                st.error("Failed to process PDF")
                return False
            
            # Create embeddings
            embeddings = EmbeddingsHandler()
            embeddings.build_vector_index([result])
            
            # Store
            st.session_state.embeddings = embeddings
            st.session_state.doc_info = result
            st.session_state.document_ready = True
            
            # Add welcome message
            st.session_state.messages.append({
                "role": "assistant",
                "content": f"‚úÖ **{result['filename']}** processed successfully!\n\nüìä **{result['word_count']:,} words** ‚Ä¢ **{result['chunk_count']} chunks**\n\nI'm ready to answer questions about your document!"
            })
            
            return True
    except Exception as e:
        st.error(f"Error: {e}")
        return False

def reset_session():
    """Reset for new document"""
    st.session_state.messages = []
    st.session_state.document_ready = False
    st.session_state.doc_info = None
    st.session_state.embeddings = None
    if hasattr(st.session_state, 'llm') and hasattr(st.session_state.llm, 'clear_memory'):
        st.session_state.llm.clear_memory()

def show_chat():
    """Display chat messages"""
    if not st.session_state.messages:
        st.markdown("""
        <div style='text-align: center; padding: 3rem; background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%); border-radius: 15px; margin: 2rem 0;'>
            <div style='font-size: 4rem; margin-bottom: 1rem;'>ü§ñ</div>
            <h2 style='color: #1e293b; margin-bottom: 1rem;'>Welcome to PDF Chatbot!</h2>
            <p style='color: #64748b; font-size: 1.1rem;'>Upload a PDF document to start an intelligent conversation about its content.</p>
        </div>
        """, unsafe_allow_html=True)
        return
    
    # Show messages
    for i, msg in enumerate(st.session_state.messages):
        if msg["role"] == "user":
            # Check for follow-up context
            context_indicator = ""
            if hasattr(st.session_state, 'llm') and hasattr(st.session_state.llm, 'detect_follow_up_question') and i > 0:
                try:
                    is_follow_up = st.session_state.llm.detect_follow_up_question(msg["content"])
                    context_indicator = " ‚Ü≥" if is_follow_up else ""
                except:
                    context_indicator = ""
            
            st.markdown(f"""
            <div class="chat-message user-message">
                <strong>You{context_indicator}:</strong><br>{msg["content"]}
            </div>
            """, unsafe_allow_html=True)
        else:
            # Show context info
            context_info = ""
            if hasattr(st.session_state, 'llm') and hasattr(st.session_state.llm, 'conversation_memory') and st.session_state.llm.conversation_memory:
                context_count = len(st.session_state.llm.conversation_memory)
                context_info = f" <small style='opacity: 0.7;'>(Context: {context_count} exchanges)</small>"
            
            # FIXED: Include the message content inside the div
            st.markdown(f"""
            <div class="chat-message ai-message">
                <strong>ü§ñ Assistant{context_info}:</strong><br>
                {msg["content"]}
            </div>
            """, unsafe_allow_html=True)

def handle_question(question):
    """Process user question with enhanced memory support"""
    # Add user message with timestamp
    current_time = datetime.now().strftime('%H:%M:%S')
    
    st.session_state.messages.append({
        "role": "user", 
        "content": question,
        "timestamp": current_time
    })
    
    if not st.session_state.document_ready:
        # FIXED: Provide helpful responses for common questions even without a document
        if question.lower() in ["how does this work?", "what can you analyze?", "upload a document"]:
            if "how does this work" in question.lower():
                response = """Here's how the PDF Chatbot works:

1. **Upload a PDF**: Use the sidebar to upload any PDF document
2. **Processing**: I'll analyze and index the content using advanced AI
3. **Ask Questions**: Type any question about the document
4. **Get Answers**: I'll provide detailed answers based on the document content

I use embeddings and language models to understand context and provide accurate responses!"""
            elif "what can you analyze" in question.lower():
                response = """I can analyze various types of PDF documents:

üìä **Business Documents**: Annual reports, financial statements, business plans
üìö **Academic Papers**: Research papers, theses, journal articles
üìã **Technical Docs**: Manuals, specifications, documentation
‚öñÔ∏è **Legal Documents**: Contracts, agreements, policies
üìñ **Books & Reports**: E-books, whitepapers, case studies

I can extract key information, summarize content, answer specific questions, and help you understand complex topics!"""
            else:  # "upload a document"
                response = """To upload a document:

1. Look at the **sidebar** on the left
2. Find the **"üìÅ Upload"** section
3. Click **"Browse files"** or drag & drop your PDF
4. Wait for processing (usually takes a few seconds)
5. Start asking questions!

Supported format: PDF files only (for now)"""
        else:
            response = """I need you to upload a PDF document first! 

Use the sidebar to upload any PDF file, and I'll analyze it for you. I can help with:
‚Ä¢ Research papers
‚Ä¢ Business reports  
‚Ä¢ Technical manuals
‚Ä¢ Legal documents
‚Ä¢ And more!"""
    else:
        try:
            # Get context
            context = st.session_state.embeddings.get_context_for_query(question, max_chunks=3)
            
            # Check if this might be a follow-up question
            is_follow_up = False
            if hasattr(st.session_state, 'llm') and hasattr(st.session_state.llm, 'detect_follow_up_question'):
                try:
                    is_follow_up = st.session_state.llm.detect_follow_up_question(question)
                except:
                    is_follow_up = False
            
            # Show follow-up indicator to user
            if is_follow_up and hasattr(st.session_state, 'llm') and hasattr(st.session_state.llm, 'conversation_memory') and st.session_state.llm.conversation_memory:
                with st.spinner("üß† Analyzing with conversation context..."):
                    response = st.session_state.llm.generate_response(
                        query=question,
                        context=context,
                        prompt_type="default"
                    )
            else:
                with st.spinner("Analyzing document..."):
                    response = st.session_state.llm.generate_response(
                        query=question,
                        context=context,
                        prompt_type="default"
                    )
            
            if not response:
                response = "I couldn't generate a response. Please try rephrasing your question."
                
        except Exception as e:
            response = f"Error: {e}. Please try again."
    
    # Add AI response with timestamp
    st.session_state.messages.append({
        "role": "assistant", 
        "content": response,
        "timestamp": current_time
    })

def main():
    """Main app with clean layout"""
    initialize_session()
    sidebar()
    
    # Document status (compact)
    if st.session_state.document_ready and st.session_state.doc_info:
        doc = st.session_state.doc_info
        st.markdown(f"""
        <div class="doc-status" style="margin-bottom: 1rem; padding: 0.8rem;">
            üìÑ <strong>{doc['filename']}</strong> Ready! ‚Ä¢ üìä {doc['word_count']:,} words ‚Ä¢ {doc['chunk_count']} chunks
        </div>
        """, unsafe_allow_html=True)
    
    # Chat area
    show_chat()
    
    # Quick questions (regular, not floating)
    if not st.session_state.document_ready:
        questions = ["How does this work?", "What can you analyze?", "Upload a document"]
    else:
        # Context-aware suggestions
        if hasattr(st.session_state, 'llm') and hasattr(st.session_state.llm, 'conversation_memory') and st.session_state.llm.conversation_memory:
            try:
                last_memory = st.session_state.llm.conversation_memory[-1]
                last_topic = last_memory['user'].lower()
                
                if 'revenue' in last_topic or 'financial' in last_topic:
                    questions = ["Tell me more", "What about expenses?", "Compare periods"]
                elif 'strategy' in last_topic or 'business' in last_topic:
                    questions = ["Elaborate", "What are risks?", "Implementation?"]
                else:
                    questions = ["More details", "Related topics?", "Summary?"]
            except:
                questions = ["Summarize document", "Main topics?", "Key insights?"]
        else:
            doc = st.session_state.doc_info
            if doc and 'annual' in doc['filename'].lower():
                questions = ["Key metrics?", "Financial highlights?", "Business strategy?"]
            elif doc and 'research' in doc['filename'].lower():
                questions = ["Research objective?", "Methodology?", "Key findings?"]
            else:
                questions = ["Summarize document", "Main topics?", "Key insights?"]
    
    st.markdown("**üí° Quick questions:**")
    cols = st.columns(len(questions))
    
    for i, q in enumerate(questions):
        with cols[i]:
            if st.button(q, key=f"quick_{i}", use_container_width=True):
                handle_question(q)
                st.rerun()
    
    # Input area (regular, not floating)
    st.markdown("### üí¨ Ask a Question")
    col1, col2 = st.columns([5, 1])
    
    with col1:
        # FIXED: Use a unique key that changes after each submission
        user_input = st.text_input(
            "Message",
            placeholder="Ask anything about your document...",
            key=f"main_input_{st.session_state.input_counter}",
            label_visibility="collapsed"
        )
    
    with col2:
        send = st.button("Send", use_container_width=True, key="main_send")
    
    # Handle input
    if send and user_input:
        handle_question(user_input)
        # Increment counter to force new input field
        st.session_state.input_counter += 1
        st.rerun()

if __name__ == "__main__":
    main()